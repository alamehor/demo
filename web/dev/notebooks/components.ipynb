{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components: Tokenizer, Lemmatizer, Lexical Attributes\n",
    "\n",
    "This notebook demonstrates the usage of `Polish` language class in spaCy. \n",
    "\n",
    "At the moment of writing this, our last pull request was not yet accepted to spaCy master branch.\n",
    "You can install spaCy from our pull request branch to reproduce our results:\n",
    "```\n",
    "pip install https://github.com/spacy-pl/spaCy/archive/pl-release/lemmatizer-tagmap-and-tests.zip\n",
    "```\n",
    "and make sure to also install a model that contains Polish POS Tagger (necessary for lemmatization to work correctly):\n",
    "```\n",
    "pip install https://storage.googleapis.com/spacy-pl-public-models/pl_model-1.0.0.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading language class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our models are not ready yet, we use a dummy tagger that always returns unknown tag. This hack is required for other language components to work correctly, but it soon won't be necessary - we will update the notebook as soon as we have the models trained and packaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.pl import Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pl_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_tadeusz = \"\"\"\n",
    "Litwo! Ojczyzno moja! ty jesteś jak zdrowie:\n",
    "Ile cię trzeba cenić, ten tylko się dowie,\n",
    "Kto cię stracił. Dziś piękność twą w całej ozdobie\n",
    "Widzę i opisuję, bo tęsknię po tobie.\n",
    "\n",
    "    Panno święta, co Jasnej bronisz Częstochowy\n",
    "I w Ostrej świecisz Bramie! Ty, co gród zamkowy\n",
    "Nowogródzki ochraniasz z jego wiernym ludem!\n",
    "Jak mnie dziecko do zdrowia powróciłaś cudem\n",
    "(Gdy od płaczącej matki, pod Twoją opiekę\n",
    "Ofiarowany, martwą podniosłem powiekę;\n",
    "I zaraz mogłem pieszo, do Twych świątyń progu\n",
    "Iść za wrócone życie podziękować Bogu),\n",
    "Tak nas powrócisz cudem na Ojczyzny łono.\n",
    "Tymczasem przenoś moją duszę utęsknioną\n",
    "Do tych pagórków leśnych, do tych łąk zielonych,\n",
    "Szeroko nad błękitnym Niemnem rozciągnionych;\n",
    "Do tych pól malowanych zbożem rozmaitem,\n",
    "Wyzłacanych pszenicą, posrebrzanych żytem;\n",
    "Gdzie bursztynowy świerzop, gryka jak śnieg biała,\n",
    "Gdzie panieńskim rumieńcem dzięcielina pała,\n",
    "A wszystko przepasane jakby wstęgą, miedzą\n",
    "Zieloną, na niej z rzadka ciche grusze siedzą.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the data\n",
    "\n",
    "Right now, the data processing takes very long (>1min for such a small document)\n",
    "due to our hack for getting a lemmatizer to work:\n",
    "\n",
    "Because we don't have a loaded POS Tagger at the moment, we created a dummy tagger\n",
    "that always returns an unknown tag. This triggers lemmatizer to search all available rules\n",
    "instead of the ones for a specific POS tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Litwo! Ojczyzno moja! ty jesteś jak zdrowie:\n",
       "Ile cię trzeba cenić, ten tylko się dowie,\n",
       "Kto cię stracił. Dziś piękność twą w całej ozdobie\n",
       "Widzę i opisuję, bo tęsknię po tobie.\n",
       "\n",
       "    Panno święta, co Jasnej bronisz Częstochowy\n",
       "I w Ostrej świecisz Bramie! Ty, co gród zamkowy\n",
       "Nowogródzki ochraniasz z jego wiernym ludem!\n",
       "Jak mnie dziecko do zdrowia powróciłaś cudem\n",
       "(Gdy od płaczącej matki, pod Twoją opiekę\n",
       "Ofiarowany, martwą podniosłem powiekę;\n",
       "I zaraz mogłem pieszo, do Twych świątyń progu\n",
       "Iść za wrócone życie podziękować Bogu),\n",
       "Tak nas powrócisz cudem na Ojczyzny łono.\n",
       "Tymczasem przenoś moją duszę utęsknioną\n",
       "Do tych pagórków leśnych, do tych łąk zielonych,\n",
       "Szeroko nad błękitnym Niemnem rozciągnionych;\n",
       "Do tych pól malowanych zbożem rozmaitem,\n",
       "Wyzłacanych pszenicą, posrebrzanych żytem;\n",
       "Gdzie bursztynowy świerzop, gryka jak śnieg biała,\n",
       "Gdzie panieńskim rumieńcem dzięcielina pała,\n",
       "A wszystko przepasane jakby wstęgą, miedzą\n",
       "Zieloną, na niej z rzadka ciche grusze siedzą."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(pan_tadeusz)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterating over tokens\n",
    "\n",
    "We can easily inspect every token in the document by iterating over it. This way, we can examine how well our lemmatizer works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: Litwo; lemma: litwa\n",
      "token: Ojczyzno; lemma: ojczyzna\n",
      "token: dowie; lemma: dować\n",
      "token: stracił; lemma: stracić\n",
      "token: całej; lemma: cały\n",
      "token: ozdobie; lemma: ozdoba\n",
      "token: Widzę; lemma: widzieć\n",
      "token: opisuję; lemma: opisywać\n",
      "token: tęsknię; lemma: tęsknić\n",
      "token: Panno; lemma: panna\n",
      "token: święta; lemma: święto\n",
      "token: bronisz; lemma: bronić\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:50]:\n",
    "    if token.is_alpha and token.lemma_ != token.lower_:\n",
    "        print(f\"token: {token.text}; lemma: {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: \n",
      " \n",
      " - alpha: False, \n",
      " - digit: False, \n",
      " - stopword: False\n",
      "Token: Litwo \n",
      " - alpha: True, \n",
      " - digit: False, \n",
      " - stopword: False\n",
      "Token: ! \n",
      " - alpha: False, \n",
      " - digit: False, \n",
      " - stopword: False\n",
      "Token: Ojczyzno \n",
      " - alpha: True, \n",
      " - digit: False, \n",
      " - stopword: False\n",
      "Token: moja \n",
      " - alpha: True, \n",
      " - digit: False, \n",
      " - stopword: True\n",
      "Token: ! \n",
      " - alpha: False, \n",
      " - digit: False, \n",
      " - stopword: False\n",
      "Token: ty \n",
      " - alpha: True, \n",
      " - digit: False, \n",
      " - stopword: True\n",
      "Token: jesteś \n",
      " - alpha: True, \n",
      " - digit: False, \n",
      " - stopword: False\n",
      "Token: jak \n",
      " - alpha: True, \n",
      " - digit: False, \n",
      " - stopword: True\n",
      "Token: zdrowie \n",
      " - alpha: True, \n",
      " - digit: False, \n",
      " - stopword: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:10]:\n",
    "    print(f\"Token: {token} \\n - alpha: {token.is_alpha}, \\n - digit: {token.is_digit}, \\n - stopword: {token.is_stop}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
